---

---
---

## 上次汇报中遗留的问题：
#### Q1.为什么特征选择时训练了线性模型，后续还要再训练一次作为最终解释结果？
- 选择特征时：训练线性模型是==选择特征的一种方法==，如下图：
![[240201-LIME算法 —— 2.1阶段性汇报-2.png]]
- 在这种默认方法中，根据两种子方法，==选择特征的依据不同==，如下图：
![[240201-LIME算法 —— 2.1阶段性汇报-3.png]]对于==红框内==：是根据这一乘积来选择特征，**而不是直接根据线性模型系数**
>因此该步骤与最终训练线性模型的步骤存在上述的区别，***不能合成一步***
#### Q2.LIME原论文中有没有提出对多维预测的解释方法？
>参考原论文:  Ribeiro, Marco Tulio, Sameer Singh和Carlos Guestrin. 《〈Why Should I Trust You?〉: Explaining the Predictions of Any Classifier》. arXiv, 2016年8月9日. 

主要内容：
- LIME算法
- SP-LIME方法：[通过解释一组单独的实例，来给出模型全局解释](zotero://note/u/LML8PHFL/)。==并不是对多维预测的解释方法==。
- LIME算法的实验
---

## 进一步的研究：
目标：改进LIME算法，将其用于[[多维预测]]模型的解释
>多维预测：将特定样本分类为特定的两个或更多类别

#### 1. 初步思考
LIME应用于多标签分类时：
- 能==独立地应用于每个标签==，为每个标签生成解释
- 无法揭示不同标签之间的==潜在关联性==
#### 2. 相关文献
没有检索到LIME领域的综述类文献，但有一篇上周见刊的LIME领域中文论文，包含了对该领域较为完整的综述。如下：
>参考：靳庆文，李胡蓉，张晨．LIME 算法的演进及其在数据故事化中的应用[J/OL]．数 据分析与知识发现. https://link.cnki.net/urlid/10.1478.G2.20240117.1106.014

LIME演进算法：
- SP-LIME：通过子模块优化，实现对模型的==全局解释==
- LIME-HPO：使用差分进化算法，优化==邻域数据生成步骤==
- DLIME：使用分层聚类，优化==邻域数据生成步骤==
- KL-LIME：结合贝叶斯投影预测变量选择方法的思想，提供==处理不同类型预测==(连续值、类标签等)的原则方法***（可能能用于多维预测的解释）***
- BayLIME：考虑先验知识，改进==不一致性==问题
- GraphLIME：进行==特征选择和可解释模型训练==步骤时，采用非线性方法
- aLIME：通过高斯分布采样，优化==邻域数据生成步骤==

目前收集到LIME领域内的论文：
- LIME演进算法相关5篇
- LIME在相关领域的应用4篇
- LIME与其它解释算法的讨论4篇
---

## 后续研究方向的规划
目标：改进LIME算法，将其用于[[多维预测]]模型的解释

1. 对上述**LIME演进算法**的相关论文：检索完全后精读，重点关注KL-LIME等可能用于多标签分类解释的演进算法
2. 对**多维预测模型的解释算法**领域：检索相关论文，阅读综述
3. 根据1.2.提出可能的改进方法
