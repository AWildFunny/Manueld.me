{
	"nodes":[
		{"id":"dd0245593cd1e586","type":"group","x":5440,"y":-800,"width":2040,"height":1800,"label":"线性回归"},
		{"id":"8fbdb79bb827a8e0","type":"group","x":2120,"y":-1240,"width":1860,"height":880,"label":"模糊认知图的Python实现"},
		{"id":"51791ca1b7e2dbcf","type":"group","x":-400,"y":-880,"width":1040,"height":1440,"label":"1.26阶段：初步解析"},
		{"id":"0c29ecb854d75bc7","type":"group","x":12640,"y":2520,"width":840,"height":1234,"label":"程序库"},
		{"id":"600f334dbdd398f9","type":"group","x":1520,"y":-1920,"width":1480,"height":600,"label":"特征选择的方法"},
		{"id":"09a4d25a775ccc82","type":"group","x":7885,"y":5440,"width":995,"height":760,"label":"数据集"},
		{"id":"7466ac191d595059","type":"group","x":5800,"y":3200,"width":580,"height":574,"label":"prompt"},
		{"id":"bfc996eb658e2371","type":"group","x":2283,"y":-1840,"width":437,"height":265,"label":"选择特征的依据"},
		{"id":"18ac30104ba64cbb","type":"file","file":"Untitled2.md","x":10910,"y":3448,"width":250,"height":215},
		{"id":"957cad6af09cc39c","type":"file","file":"Untitled1.md","x":10910,"y":3150,"width":250,"height":166},
		{"id":"59815f198dec060e","type":"file","file":"Untitled4.md","x":10910,"y":4169,"width":250,"height":155},
		{"id":"40abfe076834fda9","type":"file","file":"Untitled3.md","x":10910,"y":3813,"width":250,"height":175},
		{"id":"2d056c1ed93a6abf","type":"file","file":"梯度下降法.md","x":6580,"y":560,"width":400,"height":400},
		{"id":"95589562a7a64e7b","type":"file","file":"损失函数的分类.md","x":7040,"y":-60,"width":400,"height":400},
		{"id":"1d903277b2dc30bc","type":"file","file":"岭回归与lasso回归.md","x":6020,"y":200,"width":400,"height":400},
		{"id":"51483552dbe489a3","type":"file","file":"损失函数推导方法.md","x":6560,"y":-60,"width":400,"height":400},
		{"id":"fbc20e0263a2f9d4","type":"file","file":"VAR 系数估计方法替换.md","x":4220,"y":1590,"width":620,"height":450},
		{"id":"8c69bd68647dbbfa","type":"text","text":"为什么替换为岭回归不行？\n\t原因：\n\t- f()非线性变换后\n\t- 代码743行不再能工作（因为不能拆分为f()+f()...)\n因此，需要重写方法，先写出公式再代码实现","x":4420,"y":2308,"width":365,"height":215},
		{"id":"78caf5fed63cbd22","type":"file","file":"线性回归方法.md","x":5460,"y":-60,"width":400,"height":400},
		{"id":"ce76bc9bce0b50ad","type":"file","file":"最小二乘回归.md","x":6020,"y":-260,"width":400,"height":400},
		{"id":"b8deb3aa5b7a6005","type":"file","file":"VAR的最小二乘法参数估计过程推导.md","x":6020,"y":-720,"width":400,"height":400},
		{"id":"92b565caa87fd42d","type":"file","file":"非线性VAR损失函数梯度推导.md","x":7760,"y":-880,"width":400,"height":400},
		{"id":"c758a3145739bf25","type":"file","file":"非线性VAR损失函数推导.md","x":7760,"y":-320,"width":400,"height":400},
		{"id":"d24e61fd9430995e","type":"file","file":"VAR算法 Python库分析.md","x":4920,"y":1615,"width":400,"height":400},
		{"id":"a43ace29c10f1fc8","type":"text","text":"怎么学？\n\n1. 首先学习lasso/岭回归 的**学习过程**\n- 研究它们的损失函数\n- 推导它们的公式来源\n\n2. 从而推导出yt=f()的损失函数的公式\n3. 更进一步（尝试）：在推导出的公式中，加入类似于岭回归的正则化方法","x":4940,"y":568,"width":380,"height":292},
		{"id":"6fe10b0a1fc761d1","type":"text","text":"在哪里加入**损失函数**？\n1. 参数估计方法中（如梯度下降）","x":4220,"y":1260,"width":400,"height":130},
		{"id":"66097bfbff897244","type":"text","text":"# 后续如何改？\n1. 学\n2. 改，写出数学公式\n3. 实现后套用已有程序测试","x":5005,"y":1000,"width":250,"height":200},
		{"id":"f9f5c422424c5bdb","type":"file","file":"03-项目/24 可解释论文/修改库/dataset_main3_弃用1.py","x":9570,"y":4376,"width":400,"height":125},
		{"id":"979b4fe91be09976","type":"file","file":"03-项目/24 可解释论文/修改库/weather.csv","x":9570,"y":4621,"width":400,"height":80},
		{"id":"6578bb79e4e7a292","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch3_2.py","x":10605,"y":3846,"width":210,"height":109},
		{"id":"db6381ab3b4484fd","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch3_3.py","x":10605,"y":4189,"width":210,"height":115},
		{"id":"4fb5ee07ce9d60ce","type":"file","file":"03-项目/24 可解释论文/修改库/dataset_main3.py","x":9570,"y":4761,"width":400,"height":140},
		{"id":"807f63c667280927","type":"file","file":"03-项目/24 可解释论文/修改库/national_illness.csv","x":9570,"y":4231,"width":400,"height":70},
		{"id":"b42eebc3b30843e2","type":"file","file":"03-项目/24 可解释论文/修改库/main_test2.py","x":10265,"y":5040,"width":400,"height":400},
		{"id":"1a99bade2627eba4","type":"file","file":"预测模型评估指标.md","x":9825,"y":5040,"width":400,"height":400},
		{"id":"9da6c869c88e65da","type":"file","file":"非线性VAR测试结果.md","x":10710,"y":5040,"width":400,"height":400},
		{"id":"78b199854a9748d7","type":"text","text":"# 多重共线性\nD:\\python\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-TUE will be used.\n  self._init_dates(dates, freq)\nTraceback (most recent call last):\n  File \"D:\\Desktop\\Manueld's科研工作流\\03-项目\\24 可解释论文\\修改库\\dataset_main3.py\", line 164, in <module>\n    aic_values.append(result.aic)\n                      ^^^^^^^^^^\n  File \"D:\\python\\Lib\\site-packages\\statsmodels\\base\\wrapper.py\", line 34, in __getattribute__\n    obj = getattr(results, attr)\n          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\python\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\", line 2309, in aic\n    return self.info_criteria[\"aic\"]\n           ^^^^^^^^^^^^^^^^^^\n  File \"properties.pyx\", line 36, in pandas._libs.properties.CachedProperty.__get__\n  File \"D:\\python\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\", line 2290, in info_criteria\n    ld = logdet_symm(self.sigma_u_mle)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\python\\Lib\\site-packages\\statsmodels\\tools\\linalg.py\", line 28, in logdet_symm\n    c, _ = linalg.cho_factor(m, lower=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\python\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 154, in cho_factor\n    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=False,\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\python\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\nnumpy.linalg.LinAlgError: 8-th leading minor of the array is not positive definite\n\n进程已结束，退出代码为 1","x":10070,"y":4231,"width":270,"height":135},
		{"id":"3198ecf6415135a4","type":"text","text":"### 1. 创建并激活虚拟环境\n此处命名为`developer_1`\n```linux\npython -m venv developer_1\n```\n```linux\ndeveloper_1\\Scripts\\activate\n```\n### 2. 进入目标库\n```\nD:\ncd \"D:\\Desktop\\Manueld's科研工作流\\03-项目\\24 可解释论文\\修改库\\sklearn库-修改后\"\n```\n### 3. 安装依赖\n\n1. 更新 pip 和 setuptools：\n   ```\n   pip install --upgrade pip setuptools wheel\n   ```\n\n2. 安装编译所需的工具：\n   ```\n   pip install cython numpy scipy\n   ```\n\n### 步骤 4: 修改 setup.py（如果需要）\n\n如果您修改了文件结构或添加了新文件，可能需要更新 setup.py 中的 `extension_config` 字典。\n\n### 步骤 5: 编译和安装\n\n1. 运行以下命令来编译和安装修改后的 scikit-learn：\n   ```\n   pip install -e .\n   ```\n\n   这个命令会在\"可编辑\"模式下安装 scikit-learn，这意味着您可以继续修改源码，而不需要重新安装。\n\n### 步骤 6: 验证安装\n\n1. 打开 Python 解释器：\n   ```\n   python\n   ```\n\n2. 尝试导入您修改的模块：\n   ```python\n   import sklearn\n   print(sklearn.__file__)\n   ```\n\n   确保输出的路径指向您的自定义版本。\n\n## 3. 使用修改后的版本\n\n- 每次想要使用您的自定义版本时，请确保先激活虚拟环境。\n- 在您的 Python 脚本或 Jupyter Notebook 中，您现在可以导入并使用修改后的 scikit-learn。\n\n## 4. 注意事项\n\n- 这种方法不会影响系统级别安装的 scikit-learn。\n- 如果遇到编译错误，请检查您的修改是否引入了语法错误或不兼容的更改。\n- 对于大规模修改，可能需要更新单元测试以确保功能正常。","x":9860,"y":1415,"width":580,"height":600},
		{"id":"186d5fb7ec18c912","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch3_0.py","x":10605,"y":3172,"width":210,"height":118},
		{"id":"8aa2be21512fb7a3","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch3_1.py","x":10605,"y":3496,"width":210,"height":118},
		{"id":"bf70bc993d072134","type":"file","file":"时间序列交叉验证方法.md","x":10510,"y":2935,"width":400,"height":120},
		{"id":"4e47657f8d059ecc","type":"text","text":"# 7.4 断点\n- [x] 首先按[[Implementing Nonlinear VAR Models - Claude](https://claude.ai/chat/142e1f92-169d-4860-8e8a-c4da1904c4f1)]最后一段对话要求，修改1\n- [ ] 然后按照前面一段对话要求，修改2","x":10560,"y":2099,"width":460,"height":268},
		{"id":"1897f8cc01f49c64","type":"text","text":"## Memory Err\n在尝试分配大量内存时失败，这表明数据集过大，超出当前系统的处理能力\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.24 TiB for an array with shape (1285, 321, 1285, 321) and data type float64","x":10040,"y":3366,"width":400,"height":240},
		{"id":"62abef35d3820b2f","type":"file","file":"00-Assets/images/_sag_fast.pyx.tp","x":9780,"y":98,"width":400,"height":205},
		{"id":"222edf68dea49f40","type":"file","file":"00-Assets/images/_sag_fast.pyx","x":9780,"y":460,"width":400,"height":400},
		{"id":"48b05c35597e5551","type":"text","text":"# 7.1 断点\n结合Claude回答：\n1. 思考是否可以直接修改prediction函数，实现将改进后的VAR模型传入，代替prediction（即fx）\n2. 再思考如何实现正则化，是在prediction中实现（参考岭回归方法），还是在loss中实现？","x":10180,"y":-620,"width":320,"height":360},
		{"id":"cdd7b2b16c4a77b0","type":"text","text":"# 7.3 断点\n- [[SAG算法的Cython实现]]中，待求参数w是如何赋予初值，在每一步中是如何计算的？\n- 根据上述讨论，能否在`sag64`中改进：用待求参数w（即VAR模型中的A）乘以x（即VAR模型中的z），再对其做非线性转化，得到结果替代`predict_sample`？\n>既然非线性VAR模型中f(z*A)代表预测值，那么将var_model代码中的_estimate_var函数中计算f(z*A)的部分提取出来，从而替代sag方法中的predict_sample这一步是否就能完成修改的任务？","x":10560,"y":-663,"width":460,"height":447},
		{"id":"c4db8c275a7622ea","type":"file","file":"SAG算法的Cython实现.md","x":9320,"y":-40,"width":360,"height":480},
		{"id":"5362a8c30fa0e646","type":"file","file":"SAG算法.md","x":8800,"y":130,"width":400,"height":140},
		{"id":"5c06539dee86f17c","type":"file","file":"岭回归的Python求解代码.md","x":8800,"y":380,"width":400,"height":400},
		{"id":"c9f78a1fe486e1e3","type":"file","file":"00-Assets/images/_sag.py","x":8300,"y":130,"width":400,"height":140},
		{"id":"4672f9dfb5f191b8","type":"text","text":"# MAIN\nhttps://chatgpt.com/share/f72fad00-2405-4e3c-8b8c-b8b8821b87bd","x":8300,"y":-240,"width":400,"height":200},
		{"id":"b21834e1c1f7e368","type":"file","file":"00-Assets/images/_ridge.py","x":8300,"y":380,"width":400,"height":400},
		{"id":"25fd344646b9c700","type":"text","text":"不同模型、滞后阶数是否应该选择不同的？\n依据：拟合效果AIC","x":8910,"y":5105,"width":310,"height":120},
		{"id":"3bdc4b61f9d1dcfd","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch2_0.py","x":8810,"y":3155,"width":200,"height":120},
		{"id":"f9197833e777e578","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch2_1.py","x":8810,"y":3481,"width":200,"height":120},
		{"id":"2ddd55a7b1d506ad","type":"text","text":"改进VAR：\nyt = f(...)\n1. 对（）做非线性转换（上述f）\n- sigmoid函数\n- tanh函数\n- relu函数\n2. VAR加入损失函数\n3. 最小二乘法改为梯度下降等方法\n\n然后嵌入lime\n\n","x":3680,"y":1138,"width":340,"height":382},
		{"id":"c7b97fd987df539d","type":"text","text":"后续：如何嵌入lime？\n- 新写出的公式，作为lime中的g(z)如下图","x":3682,"y":1761,"width":338,"height":179},
		{"id":"3842627672a93d3d","type":"file","file":"00-Assets/images/Pasted image 20240528132813.png","x":3650,"y":1995,"width":400,"height":220},
		{"id":"2ac1c2ee6ecde31f","type":"text","text":"idea！\n- Zhao, Ziqi, Yucheng Shi, Shushan Wu, Fan Yang, Wenzhan Song和Ninghao Liu. 《Interpretation of Time-Series Deep Models: A Survey》, 2023年. [https://doi.org/10.48550/ARXIV.2305.14582](https://doi.org/10.48550/ARXIV.2305.14582).综述中提到VAR-SHAP","x":3053,"y":1840,"width":475,"height":200},
		{"id":"608ff9b9d15a1c90","type":"text","text":"### 建模步骤\nReference：\n- [Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models on JSTOR](https://www.jstor.org/stable/2938278?seq=1#page_scan_tab_contents)","x":3040,"y":1480,"width":500,"height":220},
		{"id":"37401d7d100ce53c","type":"file","file":"02-学科/机器学习/向量自回归（ Vector AutoRegression, VAR）模型.md","x":2740,"y":560,"width":460,"height":440},
		{"id":"c64de53b044112bf","type":"text","text":"重点\n- 理论原理\n- 程序\n\n- 是否能套入lime（替代岭回归）\n- 通过基准数据测试（多元回归预测）","x":3040,"y":1160,"width":500,"height":200},
		{"id":"431c7bceb09e87c7","type":"file","file":"02-学科/机器学习/支持向量机SVM.md","x":2720,"y":-280,"width":472,"height":480},
		{"id":"527f8f2184a20496","type":"file","file":"02-学科/机器学习/S-VAR.md","x":3420,"y":720,"width":400,"height":280},
		{"id":"121ecb0b9a93c630","type":"text","text":"[1]秦墩旺,吴立锋.模糊认知图在时间序列预测中的应用综述[J].小型微型计算机系统,2023,44(10):2314-2322.DOI:10.20009/j.cnki.21-1106/TP.2022-0729.","x":4040,"y":-885,"width":440,"height":170},
		{"id":"04f8391353b12502","type":"text","text":"# 案例对应参数解析\n2. **`y_t`**（在 `VAR.py` 中对应 `df_train` 数据）：\n    - 包含多个时间序列变量，例如 `rgnp`, `pgnp`, `ulc` 等。\n3. **`A_i`**（在 `var_model.py` 中通过 `params` 计算得到）：\n    - 系数矩阵，表示每个滞后值对当前值的影响。\n4. **`y_{t-i}`**（在 `VAR.py` 中通过 `lag_order` 和 `forecast_input` 表示）：\n    - 滞后值。例如，若滞后阶数为4，则包含前4期的观测值。\n5. **`c`**（常数项，在 `var_model.py` 中通过 `z` 中的一列常数表示）：\n    - 可以在 `z` 中添加一列全为1的常数项表示常数项 `c`。\n6. **`epsilon_t`**（误差项，通过 `resid` 计算得到）：\n    - `resid` 表示拟合模型后的残差，即预测值与实际值的差。","x":2000,"y":1085,"width":640,"height":230},
		{"id":"6ecdb4b050e1ec36","type":"file","file":"00-Assets/images/Pasted image 20240728222028.png","x":1960,"y":2638,"width":400,"height":244},
		{"id":"2002fb028bd1738c","type":"file","file":"VAR.py","x":2540,"y":1920,"width":400,"height":400},
		{"id":"e3a43e329b08ff09","type":"file","file":"VAR.ipynb","x":2540,"y":1390,"width":400,"height":400},
		{"id":"984ce6de4c04052b","type":"file","file":"03-项目/24 可解释论文/修改库/Raotbl6.csv","x":2540,"y":2560,"width":400,"height":400},
		{"id":"877a64b92f47f363","type":"text","text":"### SVM在时序预测上的应用\n\n综述：[基于支持向量机的时间序列预测方法](zotero://note/u/JBL8K5GP/)\n\n截止2019的研究：\n- 都将不同类别数据单独构建模型\n- 没有考虑不同类别数据之间的关系、即以多维数据的形式输入\n>例子：[(Mellit 等, 2013, p. 302)](zotero://note/u/J4DMCI4W/)\n>使用[[LSSVM]]对气象数据（各种类型）分别进行预测\n","x":3420,"y":-285,"width":620,"height":210},
		{"id":"687d59e0c09eeeee","type":"file","file":"02-学科/机器学习/M-SVR.md","x":3420,"y":0,"width":560,"height":200},
		{"id":"0cffa3b89d28e1bf","type":"file","file":"02-学科/机器学习/SVM的可解释性.md","x":3420,"y":240,"width":640,"height":240},
		{"id":"dd61be896834bc04","type":"file","file":"非线性转换函数.md","x":4220,"y":680,"width":400,"height":400},
		{"id":"8cc6f18da831df2b","type":"text","text":"VAR模型（不属于机器学习）**本身具备高可解释性**\n\n1. **直观的模型结构**：参数的数值可以直接解释为变量之间的相互作用。\n2. **透明的预测过程**：VAR模型的预测是通过已知的历史信息和模型参数直接计算得到的。\n4. **参数的统计显著性**：VAR模型中的参数估计通常伴随着统计检验，如t检验，可以评估每个参数的显著性。","x":3420,"y":520,"width":460,"height":160},
		{"id":"e3b7a4ccb394e2e3","type":"text","text":"[[前向选择（`'forward_selection'`）]]","x":1840,"y":-1820,"width":220,"height":57},
		{"id":"9d488c0e271a95b5","type":"text","text":"**特征选择**\n默认：[[自动选择（`'auto'`）]]","x":1540,"y":-1685,"width":250,"height":57},
		{"id":"176d0dad7ca25d6c","type":"text","text":"[[选取权重最高的特征（`'highest_weights'`）]]","x":1840,"y":-1540,"width":220,"height":57},
		{"id":"6dd8c81a9b559e21","type":"text","text":"**选择的特征**","x":2820,"y":-1702,"width":160,"height":50},
		{"id":"5758c3fa1e83ff22","type":"text","text":"处理0值","x":2280,"y":-1440,"width":125,"height":60},
		{"id":"fa6d991fc386809b","type":"text","text":"根据 **线性模型系数 与 待解释实例的值 的乘积**","x":2303,"y":-1656,"width":397,"height":61},
		{"id":"6d07e0a5cadcb054","type":"text","text":"根据**添加特征后的训练出线性模型的性能**","x":2303,"y":-1820,"width":397,"height":61},
		{"id":"b4ca2d35b6493b45","type":"text","text":"各种模型中：\n- 有没有跟多维预测有关的内容\n- 能否用一维（LIME方法）来解释？","x":2150,"y":-180,"width":370,"height":140},
		{"id":"67fb24764eeeae4f","type":"text","text":"**py-fcm/fcmpy  模糊认知图（不是模糊聚类）**\n\n\n- 模糊认知图：[[fcmpy]]，[[py-fcm]]\n- [[pythonfcm]]：[[模糊聚类FCM]]：\n- pyfcm：Firebase Cloud Messaging（FCM）的Python客户端，用于发送推送通知\n","x":2140,"y":-900,"width":580,"height":220},
		{"id":"2ce69037b6a27426","type":"file","file":"02-学科/机器学习/fcmpy.md","x":2963,"y":-1220,"width":457,"height":400},
		{"id":"47e9994ff756c1ae","type":"file","file":"02-学科/机器学习/次模挑选 SP-lime.md","x":1520,"y":-1280,"width":400,"height":400},
		{"id":"c08a8db3f3d74c22","type":"file","file":"02-学科/机器学习/多维时间序列预测.md","x":1520,"y":-800,"width":400,"height":760},
		{"id":"e91f8165aa52429e","type":"file","file":"02-学科/机器学习/LIME算法 —— 2.1阶段性汇报.md","x":880,"y":-580,"width":400,"height":400},
		{"id":"af9e3ab703a18b96","type":"file","file":"02-学科/机器学习/lime算法解析.md","x":-280,"y":-320,"width":400,"height":400},
		{"id":"a66e26be980b4e11","type":"file","file":"02-学科/机器学习/资料存档/lime/lime-wine.py","x":160,"y":180,"width":400,"height":220},
		{"id":"b3a2d0579dcf00c9","type":"file","file":"02-学科/机器学习/lime库解析.md","x":160,"y":-320,"width":400,"height":400},
		{"id":"d4fbab4319a8fb26","type":"file","file":"LIME线性模型部分与VAR对比.md","x":16240,"y":3820,"width":400,"height":400},
		{"id":"ee90c83364c98aa6","type":"file","file":"弹性网络算法测试.py","x":14280,"y":3820,"width":400,"height":400},
		{"id":"1c4affae2db66ce4","type":"text","text":"```\ndef sag_nonlinear_var(z, y_sample, nonlinear_transform, n_iter=1000, initial_step_size=0.01,\n                      step_decay=0.95, step_decay_freq=50, min_step_size=1e-6, tol=0.001,\n                      alpha=0.01, beta=0.01,batch_size = 32, patience=50,learning_rate=0.001):  # 添加 alpha 和 beta 参数，分别对应 L2 和 L1 正则化强度\n    \"\"\"\n    使用随机平均梯度(SAG)算法估计非线性VAR模型参数，并加入弹性网络正则化\n\n    参数:\n    z : ndarray, 形状为 (n_samples, n_features)，滞后变量矩阵\n    y_sample : ndarray, 形状为 (n_samples, n_targets)，当前时间点的变量值\n    nonlinear_transform : 函数，非线性变换函数，返回预测值及其导数\n    n_iter : int, 最大迭代次数\n    initial_step_size : float, 初始学习率\n    step_decay : float, 学习率衰减率\n    step_decay_freq : int, 学习率衰减频率（每多少次迭代衰减一次）\n    min_step_size : float, 最小学习率\n    tol : float, 收敛容差\n    alpha : float, L2正则化参数\n    beta : float, L1正则化参数\n\n    返回:\n    params : ndarray, 估计的模型参数\n    \"\"\"\n    print(f\"-- 初始参数 --\\n初始学习率: {initial_step_size:.6f}, 衰减率：{step_decay}, 衰减频率: {step_decay_freq}, 最小学习率: {min_step_size:.6f}\")\n    print(f\"L2正则化参数 alpha: {alpha:.6f}, L1正则化参数 beta: {beta:.6f}\\n-- --\")\n\n    n_samples, n_features = z.shape\n    n_targets = y_sample.shape[1]\n\n    # 初始化参数\n    params = np.zeros((n_features, n_targets))\n    sum_gradients = np.zeros_like(params)\n    gradient_memory = np.zeros((n_samples, n_features, n_targets))\n    step_size = initial_step_size\n\n    for iteration in range(n_iter):\n        indices = np.random.permutation(n_samples)\n        max_param_change = 0\n\n        for i in indices:\n            x_i = z[i]\n            y_i = y_sample[i]\n\n            # 计算预测值和非线性变换的导数\n            prediction, derivative = nonlinear_transform(np.dot(x_i, params))\n\n            # 计算损失函数梯度\n            error = prediction - y_i\n            gradient = np.outer(x_i, error * derivative)\n\n            # 添加 L2 正则化梯度\n            gradient += alpha * params\n\n            # 添加 L1 正则化梯度（使用次梯度方法）\n            l1_grad = beta * np.sign(params)\n            gradient += l1_grad\n\n            # 梯度裁剪\n            max_grad = 10  # 可以根据需要调整这个阈值\n            gradient = np.clip(gradient, -max_grad, max_grad)\n\n            # 更新平均梯度\n            gradient_correction = gradient - gradient_memory[i]\n            sum_gradients += gradient_correction\n            gradient_memory[i] = gradient\n\n            # 更新参数\n            param_change = step_size * (sum_gradients / n_samples)\n            params -= param_change\n\n            # 实现 L1 正则化的软阈值处理\n            threshold = beta * step_size\n            params = np.sign(params) * np.maximum(np.abs(params) - threshold, 0)\n\n            # 更新最大参数变化\n            max_param_change = max(max_param_change, np.max(np.abs(param_change)))\n\n        # 检查收敛性\n        if max_param_change < tol:\n            print(f\"== 迭代{iteration+1}次后达到收敛 ==\")\n            break\n\n        # 学习率衰减\n        if (iteration + 1) % step_decay_freq == 0:\n            step_size = max(step_size * step_decay, min_step_size)\n            print(f\"第{iteration+1}次迭代, 学习率调整为: {step_size:.6f}\")\n\n        # 每100次迭代打印一次进度\n        if (iteration + 1) % 100 == 0:\n            print(f\"第{iteration+1}次迭代中：Max param change: {max_param_change}\")\n\n    else:\n        print(f\"== 迭代({n_iter})次后：未达到收敛 ==\\n\")\n\n    return params\n```\n以上是我目前的函数，请你将早停法融合进来，给我一个完整的函数。要求：\n1. 注释详细，即原有的不删去、考虑添加更多的，并在注释中尽可能详细地解释每个函数、变量和操作的作用，使得我在原有代码的基础上能直接读懂新代码的任何段落\n2. 测试信息详细，在原有测试信息的基础上添加，使我能够监控整个过程、发现错误\n3. 控制台输出信息美观，能让我清楚了解参数拟合过程\n","x":14510,"y":4301,"width":340,"height":280},
		{"id":"9314bea0e3938840","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME 库文件/models.py","x":13060,"y":3071,"width":400,"height":120},
		{"id":"034b1400999cf4c8","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME 库文件/test_main1.py","x":12860,"y":3901,"width":400,"height":400},
		{"id":"524b937149953388","type":"file","file":"02-学科/机器学习/py-fcm.md","x":2963,"y":-780,"width":457,"height":400},
		{"id":"ae9f1d8dc4058592","type":"text","text":"#机器学习/lime算法 \n#Python/lime库 ","x":-530,"y":-1120,"width":250,"height":80},
		{"id":"ef8b5f1ac41929ee","type":"text","text":"# 第二阶段核心问题\nQ1 ：[[explain_instance_with_data方法#3. 特征选择]]中：训练线性模型的方法\nQ2： **如何利用lime解释多结果维度的数据？** 阅读论文\nQ3：如何用lime方法解释[[多维预测]]？","x":880,"y":-900,"width":420,"height":225},
		{"id":"b8344a6c89653551","type":"file","file":"00-Assets/汇报/可解释机器学习 LIME 方法的解析-Beamer.pdf","subpath":"#page=1","x":-80,"y":-760,"width":400,"height":400},
		{"id":"1177d19b303e49fc","type":"file","file":"02-学科/机器学习/fcmpy与py-fcm的区别.md","x":3560,"y":-920,"width":400,"height":240},
		{"id":"1003994ac4b35403","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch4_0.py","x":11328,"y":3172,"width":220,"height":118},
		{"id":"6945415c4d03a64a","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch4_0_1.py","x":11328,"y":3394,"width":220,"height":108},
		{"id":"6bf2a78d4aa37561","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch4_0_test1.py","x":11328,"y":3609,"width":220,"height":108},
		{"id":"c00d3867944a87fe","type":"text","text":"# Prompt\n\n# VAR 模型分析项目\n\n## 项目概述\n\n这是一个用于向量自回归（VAR）模型分析的 Python 项目。项目的主要目标是加载时间序列数据，拟合多种 VAR 模型（包括线性和非线性），进行预测，并评估、比较各个模型的性能。\n\n## 文件结构及功能\n\n1. `models.py`: 包含所有 VAR 模型类的定义，包括线性 VAR 和各种非线性 VAR 模型。\n2. `estimation.py`: 包含用于估计 VAR 模型参数的算法，如随机平均梯度（SAG）算法。\n3. `forecasting.py`: 包含用于 VAR 模型预测的函数。\n4. `evaluation.py`: 包含用于评估和可视化 VAR 模型性能的函数。\n5. `main.py`: 主程序，协调其他模块，完成多个模型在一个数据集上的测试\n\n## 使用说明\n\n作为一个 AI 助手，您的任务是帮助用户修改和优化这个项目。在回答用户的问题或提供建议时，请遵循以下指导：\n\n1. 清晰指出需要修改的文件和具体代码位置。\n2. 提供简洁的步骤指引，帮助用户进行修改。\n3. 在提供新的或修改后的代码时，添加详尽的中文注释。\n4. 如果修改涉及多个文件，请明确说明每个文件的变更。\n5. 在适当的时候，建议优化代码结构以提高可读性和效率。\n6. 如果用户的请求不明确，主动询问以clarify需求。\n\n示例回答格式：\n\n```\n要实现您的需求，我们需要修改以下文件：\n\n1. `models.py`\n   在 [具体行号] 处添加/修改以下代码：\n   ```python\n   # 详细的中文注释\n   # 解释代码的功能和作用\n   def new_function():\n       # 函数实现\n   ```\n\n2. `main.py`\n   在 [具体行号] 处更新以下内容：\n   ```python\n   # 更新原因的解释\n   updated_code_here()\n   ```\n\n这些修改将实现 [简要说明实现的功能]。您还需要注意 [任何需要特别注意的点]。\n","x":12790,"y":2203,"width":540,"height":167},
		{"id":"31e6aab4862322d8","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME 库文件/main.py","x":12660,"y":2564,"width":400,"height":400},
		{"id":"0d144526d4512afd","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME 库文件/estimation.py","x":13060,"y":3254,"width":400,"height":120},
		{"id":"8f511b14ac408c67","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME 库文件/forecasting.py","x":13060,"y":3431,"width":400,"height":120},
		{"id":"9381d166460e5478","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME 库文件/evaluation.py","x":13060,"y":3631,"width":400,"height":103},
		{"id":"295c4ea3cf8ea5fd","type":"file","file":"多维时间序列预测可解释方法的评估指标.md","x":14769,"y":3820,"width":400,"height":400},
		{"id":"4dbf5d1b495d845f","type":"text","text":"# 7.5 断点\n\n- [ ] 研究pyx文件生成pyd文件的过程，将其编译为pyd文件","x":11070,"y":1715,"width":460,"height":180},
		{"id":"5014e2782b336901","type":"text","text":"目前基于第一个数据集的测试结果是，使用梯度下降的VAR比使用最小二乘法的VAR预测效果更好，在效果上和ReLUVAR相近。\n可以预见的是，在另外几个数据集上它的效果应该也和ReLUVAR相近，因为ReLUVAR本身只是在使用梯度下降的VAR上加了个绝对值的非线性转换。","x":11313,"y":3793,"width":250,"height":148},
		{"id":"1913fec9a54c3742","type":"file","file":"VAR的最小二乘法参数估计过程推导.md","x":11615,"y":2912,"width":250,"height":143},
		{"id":"cfedd69d22654f1c","type":"file","file":"03-项目/24 可解释论文/修改库_process2/VAR改进+LIME_main.py","x":12030,"y":2560,"width":400,"height":400},
		{"id":"012da175781aa26e","type":"file","file":"代码功能结构优化建议.md","x":12030,"y":3463,"width":400,"height":400},
		{"id":"927674bc04d2d987","type":"text","text":"1. **梯度累积和溢出问题**：\n    \n    - `sag_nonlinear_var` 函数中的梯度累积步骤容易导致溢出，尤其是当应用在线性模型中时。具体来说，这段代码：\n    \n    ```python\n    pythonsum_gradients += gradient_correction\n    ```\n    \n    - 在多个迭代后，`sum_gradients`可能会变得非常大，特别是如果使用恒等变换的话，梯度的变化非常快，可能会导致数值溢出，从而使得整个模型的参数更新过程失效。\n2. **`nan` 值产生的原因**：\n    \n    - 溢出导致的梯度累积将导致计算中的`nan`值。特别是在计算`params`时，数值上的问题会逐步传播，最终导致所有相关的结果（如`residuals`, `forecast`等）都变为`nan`。\n3. **数值不稳定**：\n    \n    - 由于线性模型本质上不适合使用`SAG`算法，您会遇到梯度累积和更新问题，这会导致训练时的数值不稳定性，从而使整个模型训练过程失败。","x":11615,"y":3161,"width":250,"height":140},
		{"id":"fe210c40436e1b5e","type":"text","text":"==放弃在原sag上改进的思路==\n新方向：python重写梯度下降算法求参","x":11640,"y":2203,"width":390,"height":60},
		{"id":"f7835f1a6db8f5f8","type":"file","file":"03-项目/24 可解释论文/修改库/_sag_fast.pyx","x":11100,"y":1967,"width":400,"height":400},
		{"id":"2c15712f06d9c4b8","type":"text","text":"线性VAR模型也使用梯度下降方法进行测试\n- 保持一致性","x":11315,"y":2912,"width":245,"height":143},
		{"id":"8378539c4bf78ec3","type":"file","file":"学习率（步长）的选择方法.md","x":7885,"y":4080,"width":400,"height":400},
		{"id":"052971c623105b30","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch2_3_弃用1.py","x":8810,"y":4301,"width":200,"height":120},
		{"id":"ebd5a5e899c111a0","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch2_3.py","x":8810,"y":4701,"width":200,"height":120},
		{"id":"211407dcce738225","type":"file","file":"03-项目/24 可解释论文/修改库/ETTh1.csv","x":9570,"y":3811,"width":400,"height":115},
		{"id":"cfc437b44f436365","type":"file","file":"ETT-small数据集.md","x":9090,"y":3781,"width":400,"height":290},
		{"id":"2e9ec6ded179ed12","type":"file","file":"03-项目/24 可解释论文/修改库/dataset_main2.py","x":9570,"y":3996,"width":400,"height":120},
		{"id":"e8686ca57b6a9908","type":"text","text":"假如我正在做一项关于可解释机器学习算法的改进，想对我改进后的模型进行测试。在我的模型涉及到的多维时间序列预测领域，相关研究一般采用什么样的数据集进行模型测试评估？请你从知识库和网络进行广泛检索，要求给出一系列数据集及其论文，要求：\n- 数据集质量高，包含足够的数据量。\n- 论文及数据集权威性、认可性及其在我使用场景上的适用性高\n- 有公开的基准结果，可以比较你的算法性能。","x":7940,"y":5460,"width":480,"height":100},
		{"id":"44aedd103c916c66","type":"file","file":"VAR模型-常用数据集.md","x":7940,"y":5680,"width":400,"height":400},
		{"id":"061ea4cd47127324","type":"file","file":"可解释预测-常用数据集.md","x":8420,"y":5680,"width":400,"height":390},
		{"id":"75493981c9b5c9aa","type":"file","file":"03-项目/24 可解释论文/修改库/main_test1.py","x":8420,"y":4965,"width":400,"height":400},
		{"id":"1ab1321707ff3802","type":"file","file":"03-项目/24 可解释论文/修改库/electricity.csv","x":9570,"y":3426,"width":400,"height":120},
		{"id":"1c67654c7941ec60","type":"file","file":"03-项目/24 可解释论文/修改库/dataset_main1.py","x":9570,"y":3646,"width":400,"height":105},
		{"id":"63e23d085f303857","type":"file","file":"03-项目/24 可解释论文/修改库/Raotbl6.csv","x":9570,"y":3157,"width":400,"height":117},
		{"id":"b0ca9ceb71e805c1","type":"file","file":"weather数据集.md","x":9090,"y":4621,"width":400,"height":280},
		{"id":"1226c15d83bc4205","type":"file","file":"illness数据集.md","x":9090,"y":4221,"width":400,"height":280},
		{"id":"9f14879595285b06","type":"file","file":"Raotbl数据集.md","x":9090,"y":3098,"width":400,"height":235},
		{"id":"037acbd041fc5302","type":"file","file":"eletricity数据集.md","x":9090,"y":3426,"width":400,"height":230},
		{"id":"a7f4859a6280c5e7","type":"file","file":"随机梯度下降SGD与随机平均梯度下降SAG算法.md","x":9120,"y":1040,"width":400,"height":200},
		{"id":"54c32f6d00c391d2","type":"file","file":"梯度下降改进.py","x":8300,"y":920,"width":400,"height":400},
		{"id":"61751582cd0f0823","type":"text","text":"# 改进思路\n\n## 1. 修改VAR为非线性\n- 数学推导：[[非线性VAR损失函数推导]]\n- 代码实现：思路[非线性VAR改进-基础1 - Claude](https://claude.ai/chat/dde0847f-de14-43cd-808a-ea0e8bcdede7)\n\t1. 修改[[VAR算法 Python库分析#^31283c| predict方法]]中的forecast生成预测值步骤：实现**生成预测值**时的改进\n\t2. ==关键点==：修改[[_estimate_var方法]]中参数估计部分：实现**拟合模型**时的改进","x":8330,"y":2320,"width":680,"height":317},
		{"id":"2cd50e2fa64f671f","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch1_5.py","x":7105,"y":4935,"width":225,"height":170},
		{"id":"ccbf1a09bb69825b","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch1_3.py","x":7105,"y":4200,"width":225,"height":160},
		{"id":"f7ffb8a7f232745c","type":"text","text":"我已仔细检查了您提供的代码。总体来说，这个实现基本满足了非线性VAR算法的要求。不过，我发现了一些需要修改和优化的地方：\n\n1. 在`NonlinearVAR`类中，`nonlinear_transform`被定义为一个方法，但在`__init__`中被设置为None。这可能会导致混淆。建议将其改为一个抽象方法：\n\npython\n\nCopy\n\n`from abc import ABC, abstractmethod class NonlinearVAR(VAR, ABC):     @abstractmethod    def nonlinear_transform(self, x):        pass`\n\n2. 在`_estimate_var`方法中，您使用了`minimize`函数，但没有导入。需要添加：\n\npython\n\nCopy\n\n`from scipy.optimize import minimize`\n\n3. 在主程序中，您使用了`method='sag'`，但这个方法并未在`_estimate_var`中定义。您可能想要使用`'nonlinear'`：\n\npython\n\nCopy\n\n`nonlinear_results = nonlinear_model.fit(maxlags=4, method='nonlinear', verbose=True)`\n\n4. `NonlinearVARResults`类中的`plot_forecast`方法直接调用了线性模型的方法。这可能不适用于非线性模型，需要重新实现这个方法以考虑非线性性。\n5. 在非线性估计中，您可能想要添加正则化项以防止过拟合：\n\npython\n\nCopy\n\n`def objective(params):     params_reshaped = params.reshape(z.shape[1], y_sample.shape[1])    pred = self.nonlinear_transform(z @ params_reshaped)    return np.sum((y_sample - pred) ** 2) + alpha * np.sum(params**2)  # L2正则化`\n\n6. 考虑添加一个方法来计算非线性模型的预测区间，这可能需要使用蒙特卡洛方法。\n7. 在`SigmoidVAR`类中，`nonlinear_transform`方法覆盖了父类的属性。这可能会导致问题。建议重命名为`sigmoid_transform`：\n\npython\n\nCopy\n\n`class SigmoidVAR(NonlinearVAR):     def __init__(self, endog, exog=None, dates=None, freq=None, missing='none'):        super().__init__(endog, exog, dates, freq, missing)        self.nonlinear_transform = self.sigmoid_transform     def sigmoid_transform(self, x):        return 1 / (1 + np.exp(-x))`\n\n8. 考虑添加更多的非线性变换选项，如tanh或ReLU函数。\n9. 在评估部分，考虑添加一些统计检验，如ADF检验来检查残差的平稳性。\n10. 最后，考虑添加一些单元测试来确保非线性VAR模型的正确性。\n\n这些修改将使您的非线性VAR实现更加健壮和灵活。同时，它也会更好地处理非线性预测和评估。请根据您的具体需求来实施这些建议。","x":7500,"y":3100,"width":460,"height":440},
		{"id":"db1adccaec5b1185","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch1_2.py","x":7105,"y":3720,"width":225,"height":140},
		{"id":"27a208fb8e01d9b2","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进main.py","x":7760,"y":2560,"width":400,"height":400},
		{"id":"7c5e84aefb52d5d9","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch1_1.py","x":7110,"y":3140,"width":220,"height":120},
		{"id":"7b2efcbeb8aba4cd","type":"text","text":"Step Decay是一种学习率调度策略，在训练过程中按预定的步骤减小学习率。通常每隔一定的训练迭代次数（epochs或steps）将学习率乘以一个小于1的常数，例如0.5或0.1。这种方法的具体公式为：\n\n![[Pasted image 20240728112856.png]]\n\n其中：\n\n- η 是当前学习率\n- η0​ 是初始学习率\n- decay_rate 是衰减率（如0.5或0.1）\n- decay_steps 是每隔多少步进行一次衰减\n\n**优点**：\n\n- 简单易实现\n- 在训练初期以较大学习率快速接近最优解，后期以较小学习率进行微调\n\n**缺点**：\n\n- 衰减策略可能需要人工调参，不同数据集和任务需要不同的参数配置\n- 衰减过程是离散的，可能导致学习率的突变，不够平滑","x":7460,"y":4580,"width":425,"height":165},
		{"id":"e70205d32365e0cc","type":"text","text":"后两个非线性模型，拟合次数为1和1000未收敛两个极端，需要进行修改\n![[Pasted image 20240721181536.png]]","x":7420,"y":4105,"width":400,"height":350},
		{"id":"85d2e4ffab4ee54e","type":"file","file":"00-Assets/images/Pasted image 20240728210026.png","x":7487,"y":4820,"width":398,"height":400},
		{"id":"a4bdd3640a5b992d","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch1_4.py","x":7105,"y":4580,"width":225,"height":165},
		{"id":"5a8d1048f671d7c2","type":"file","file":"00-Assets/images/Pasted image 20240721180742.png","x":6580,"y":4080,"width":400,"height":400},
		{"id":"46b2870115e6defb","type":"file","file":"VAR模型中的param与coef参数.md","x":5500,"y":4580,"width":480,"height":240},
		{"id":"36d233b84fe1f759","type":"file","file":"VAR模型预测过程.md","x":5500,"y":4920,"width":480,"height":200},
		{"id":"7d4e5bda8eec6a51","type":"file","file":"信息准则（AIC、BIC等）.md","x":6580,"y":4563,"width":400,"height":200},
		{"id":"72ed8382a2b87964","type":"text","text":"根据我上传的“非线性VAR损失函数推导.md”中涉及到的非线性VAR模型原理，我在对VAR模型进行改进，我上传的.py文件是我改进后的代码。目前，该代码的改进非线性VAR模型还存在许多问题，我将基于该代码进行改进。\n假如你是编程高手和机器学习专家，请你结合我上传的文件中的数学原理和代码，指导我进行改进，首先提出一些可行的改进方向。要求：仔细分析，分步回答","x":5820,"y":3231,"width":540,"height":220},
		{"id":"b6202f2ca3d25bb0","type":"text","text":"以上是我改进后代码的执行结果。综合执行结果、实际代码与数学原理，请分析：\n1. 模型的拟合过程是否正常、拟合效果如何？\n2. 模型的预测效果如何？\n3. 改进后的模型相比于原模型如何？\n4. 为了使得模型更好，下一步应该如何改进？","x":5820,"y":3516,"width":540,"height":238},
		{"id":"b2d593472a4fdc8a","type":"file","file":"03-项目/24 可解释论文/修改库/VAR_改进branch2_2.py","x":8810,"y":3856,"width":200,"height":140},
		{"id":"8e7e4f8a60ba1b6e","type":"text","text":"### 1. 可解释预测的数据集\n需要该领域的全部数据集，来证明方法的优越性\n### 2. 尝试代入可解释预测方法（LIME）\n一般主要是看==预测结果准确度==\n### 3. 修改预测方法\n不使用单一的训练集与数据集，而是采用**K折交叉验证**等方法","x":8170,"y":3151,"width":370,"height":330},
		{"id":"1cb785f04c8cb637","type":"text","text":"# 7.16 断点\n- 正则化`wscale`系数：\n\t- 讨论是否能适用同样的思路\n\t- 若不能，直接在损失函数加入正则化系数\n- 预测`forecast`：\n\t- 研究其预测步骤\n\t- 直接应用非线性转换or分步应用","x":7460,"y":3641,"width":460,"height":300},
		{"id":"681bfb526b66f519","type":"file","file":"00-Assets/images/Pasted image 20240715155217.png","x":6580,"y":3591,"width":400,"height":399},
		{"id":"41c8e52e6f06771b","type":"file","file":"_estimate_var方法.md","x":5760,"y":1440,"width":360,"height":480},
		{"id":"82dd9845df1af463","type":"file","file":"fit方法.md","x":5480,"y":1440,"width":200,"height":240},
		{"id":"a3d4b998737af5d0","type":"file","file":"VAR.py","x":6980,"y":1120,"width":400,"height":400},
		{"id":"7acb15692f723b12","type":"text","text":"相关文件\n- D:\\python\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\n- D:\\Desktop\\Manueld's科研工作流\\VAR.py\n\n你是VAR模型助手，帮助一名对编程和机器学习知识掌握不足的本科生进行关于改进VAR算法的研究。你的目标是提供清晰易懂的解释，使用提供的VAR代码文件中的实例，帮助理解VAR算法，提出改进建议，并逐步解释修改，参考提供的Python源文件。你需要对以下文件进行解释和参考：\n\n1. 我上传的VAR.py，代表VAR代码示例文件：结合该文件中的实例进行解释，使每个研究和改进步骤对应到该示例文件中的案例步骤。\n\n2. 我上传的var_model.py，代表VARmodel的Python源文件：这是后续解析的基础文件，所有的修改和改进都基于这个文件。\n\n  \n假如我要对VAR算法进行改进，主要是从var_model文件中的第743行使用的OLS参数估计方法进行替换，将其修改为梯度下降、岭回归等方法，并基于VAR.py的数据集，评估比较不同方法的预测效果。\n\n请你提出一套方案，用以实现，要求最好不修改上述两文件，而是单独在一个文件中调用实现。\n\n最后，请根据你提出的方案，结合上述两个文件的代码，撰写详细的var_param_estimation.py文件，实现上述功能。\n\n注意：你的方案中，尽可能基于VAR.py已经处理过的数据进行测试，并重写和复用我上传的文件中的变量、方法等。同时尽可能多使用中文注释，使我能够明白程序的意思","x":6420,"y":1380,"width":360,"height":420},
		{"id":"03e0a566743b9a7c","type":"file","file":"00-Assets/images/Pasted image 20240713203732.png","x":6580,"y":2996,"width":400,"height":408},
		{"id":"cb6291e8500e91f5","type":"file","file":"VAR_改进branch3.py","x":5740,"y":2015,"width":400,"height":400},
		{"id":"45d90340fbc8bd4c","type":"file","file":"00-Assets/images/var_model 1.py","x":6980,"y":1590,"width":400,"height":400},
		{"id":"b941c7b774c33402","type":"file","file":"SAG与SGD的Python实现.md","x":9580,"y":1040,"width":400,"height":200},
		{"id":"aac756eb594c47e8","type":"file","file":"VAR_改进main.py","x":7760,"y":2015,"width":400,"height":400}
	],
	"edges":[
		{"id":"6b7397656a3042c3","fromNode":"51791ca1b7e2dbcf","fromSide":"right","toNode":"ef8b5f1ac41929ee","toSide":"left"},
		{"id":"007b229d9882aec2","fromNode":"ef8b5f1ac41929ee","fromSide":"right","toNode":"47e9994ff756c1ae","toSide":"left","label":"Q2"},
		{"id":"6705867aad959a40","fromNode":"9d488c0e271a95b5","fromSide":"top","toNode":"e3b7a4ccb394e2e3","toSide":"left","label":"若特征数少(<6)"},
		{"id":"4d9fc8ef0adf9128","fromNode":"9d488c0e271a95b5","fromSide":"bottom","toNode":"176d0dad7ca25d6c","toSide":"left","label":"若特征数多(>=6)"},
		{"id":"57d4f19c1d95f3d8","fromNode":"176d0dad7ca25d6c","fromSide":"right","toNode":"fa6d991fc386809b","toSide":"left","label":"数据非稀疏"},
		{"id":"1d54c41766c3b179","fromNode":"176d0dad7ca25d6c","fromSide":"right","toNode":"5758c3fa1e83ff22","toSide":"left","label":"数据稀疏"},
		{"id":"1af12ec4572c16ec","fromNode":"5758c3fa1e83ff22","fromSide":"right","toNode":"fa6d991fc386809b","toSide":"bottom"},
		{"id":"5f7e2c60f0c52eca","fromNode":"e3b7a4ccb394e2e3","fromSide":"right","toNode":"6d07e0a5cadcb054","toSide":"left"},
		{"id":"15443cd109e998c1","fromNode":"bfc996eb658e2371","fromSide":"right","toNode":"6dd8c81a9b559e21","toSide":"left"},
		{"id":"4ea41473eca9d13a","fromNode":"ef8b5f1ac41929ee","fromSide":"right","toNode":"600f334dbdd398f9","toSide":"left","label":"Q1"},
		{"id":"44eeb23373b163a5","fromNode":"ef8b5f1ac41929ee","fromSide":"bottom","toNode":"e91f8165aa52429e","toSide":"top"},
		{"id":"b35bd4865ea82aeb","fromNode":"ef8b5f1ac41929ee","fromSide":"right","toNode":"c08a8db3f3d74c22","toSide":"left","label":"Q3"},
		{"id":"b7b632d6c766ae6c","fromNode":"67fb24764eeeae4f","fromSide":"right","toNode":"2ce69037b6a27426","toSide":"left","label":"fcmpy"},
		{"id":"3acb76b8ea68e72b","fromNode":"67fb24764eeeae4f","fromSide":"right","toNode":"524b937149953388","toSide":"left","label":"py-fcm"},
		{"id":"612d7ba08e323926","fromNode":"524b937149953388","fromSide":"right","toNode":"1177d19b303e49fc","toSide":"left"},
		{"id":"8585def8a4c7b0df","fromNode":"2ce69037b6a27426","fromSide":"right","toNode":"1177d19b303e49fc","toSide":"left"},
		{"id":"93eeeef9ad4ecadc","fromNode":"b4ca2d35b6493b45","fromSide":"right","toNode":"431c7bceb09e87c7","toSide":"left"},
		{"id":"08d2c48a02502b77","fromNode":"b4ca2d35b6493b45","fromSide":"right","toNode":"37401d7d100ce53c","toSide":"left"},
		{"id":"f9e3309c296b22b3","fromNode":"c08a8db3f3d74c22","fromSide":"right","toNode":"8fbdb79bb827a8e0","toSide":"left"},
		{"id":"792051efc7dedcb8","fromNode":"c08a8db3f3d74c22","fromSide":"right","toNode":"b4ca2d35b6493b45","toSide":"left"},
		{"id":"6bc7ff9b70842d41","fromNode":"431c7bceb09e87c7","fromSide":"right","toNode":"877a64b92f47f363","toSide":"left","label":"传统一维"},
		{"id":"1569f30e3e6563bb","fromNode":"431c7bceb09e87c7","fromSide":"right","toNode":"687d59e0c09eeeee","toSide":"left","label":"多维"},
		{"id":"836b1eb0f7ce1617","fromNode":"37401d7d100ce53c","fromSide":"right","toNode":"527f8f2184a20496","toSide":"left","label":"结构化"},
		{"id":"397eb5e490eb01cd","fromNode":"431c7bceb09e87c7","fromSide":"bottom","toNode":"0cffa3b89d28e1bf","toSide":"left","label":"可解释性"},
		{"id":"c9fdcc6fd028dd7f","fromNode":"37401d7d100ce53c","fromSide":"right","toNode":"8cc6f18da831df2b","toSide":"left","label":"可解释性"},
		{"id":"9e60d5fa23f125f7","fromNode":"37401d7d100ce53c","fromSide":"bottom","toNode":"c64de53b044112bf","toSide":"top"},
		{"id":"b285ab104b8a4693","fromNode":"527f8f2184a20496","fromSide":"bottom","toNode":"c64de53b044112bf","toSide":"top"},
		{"id":"e710681627a11cde","fromNode":"8fbdb79bb827a8e0","fromSide":"right","toNode":"121ecb0b9a93c630","toSide":"left"},
		{"id":"790b32f5e579b180","fromNode":"c64de53b044112bf","fromSide":"bottom","toNode":"608ff9b9d15a1c90","toSide":"top"},
		{"id":"be6fb563020dafc7","fromNode":"608ff9b9d15a1c90","fromSide":"left","toNode":"e3a43e329b08ff09","toSide":"right"},
		{"id":"bbec42fd8c7af561","fromNode":"c64de53b044112bf","fromSide":"right","toNode":"2ddd55a7b1d506ad","toSide":"left"},
		{"id":"ab91db4d2fd0403b","fromNode":"b3a2d0579dcf00c9","fromSide":"bottom","toNode":"a66e26be980b4e11","toSide":"top"},
		{"id":"4fc0ee39e01801c5","fromNode":"2ddd55a7b1d506ad","fromSide":"right","toNode":"dd61be896834bc04","toSide":"left","label":"1"},
		{"id":"8c0f84f40b31a2c5","fromNode":"2ddd55a7b1d506ad","fromSide":"right","toNode":"fbc20e0263a2f9d4","toSide":"left","label":"3"},
		{"id":"ddba89a3219758ae","fromNode":"fbc20e0263a2f9d4","fromSide":"right","toNode":"d24e61fd9430995e","toSide":"left"},
		{"id":"d4a0229f42b2a667","fromNode":"d24e61fd9430995e","fromSide":"right","toNode":"82dd9845df1af463","toSide":"left"},
		{"id":"f12dab3b3998d513","fromNode":"82dd9845df1af463","fromSide":"right","toNode":"41c8e52e6f06771b","toSide":"left"},
		{"id":"f748ce762c0df109","fromNode":"e3a43e329b08ff09","fromSide":"left","toNode":"04f8391353b12502","toSide":"bottom"},
		{"id":"2b5e4caf9e49ce68","fromNode":"37401d7d100ce53c","fromSide":"left","toNode":"04f8391353b12502","toSide":"top"},
		{"id":"08d665c9ded225e6","fromNode":"41c8e52e6f06771b","fromSide":"bottom","toNode":"cb6291e8500e91f5","toSide":"top"},
		{"id":"86ff280b347fbd30","fromNode":"fbc20e0263a2f9d4","fromSide":"bottom","toNode":"cb6291e8500e91f5","toSide":"left"},
		{"id":"8a9549b16146d7a8","fromNode":"6fe10b0a1fc761d1","fromSide":"bottom","toNode":"fbc20e0263a2f9d4","toSide":"top","label":"1"},
		{"id":"c7857dade565f8e6","fromNode":"2ddd55a7b1d506ad","fromSide":"right","toNode":"6fe10b0a1fc761d1","toSide":"left","label":"2"},
		{"id":"eb8d35ba0b40e128","fromNode":"7acb15692f723b12","fromSide":"right","toNode":"a3d4b998737af5d0","toSide":"left"},
		{"id":"6b90fd8ad783f36e","fromNode":"7acb15692f723b12","fromSide":"right","toNode":"45d90340fbc8bd4c","toSide":"left"},
		{"id":"69ab5338baa7f4ab","fromNode":"2ddd55a7b1d506ad","fromSide":"bottom","toNode":"c7b97fd987df539d","toSide":"top"},
		{"id":"8fe68ec454a64e7a","fromNode":"c7b97fd987df539d","fromSide":"bottom","toNode":"3842627672a93d3d","toSide":"top"},
		{"id":"ef8bf9f417c90be9","fromNode":"fbc20e0263a2f9d4","fromSide":"bottom","toNode":"8c69bd68647dbbfa","toSide":"top"},
		{"id":"ee66df84be019aa4","fromNode":"66097bfbff897244","fromSide":"bottom","toNode":"2ddd55a7b1d506ad","toSide":"top","label":"2"},
		{"id":"2e571e6f17c37c07","fromNode":"66097bfbff897244","fromSide":"bottom","toNode":"cb6291e8500e91f5","toSide":"left","label":"3"},
		{"id":"8060cac6bd5379d3","fromNode":"78caf5fed63cbd22","fromSide":"right","toNode":"1d903277b2dc30bc","toSide":"left"},
		{"id":"cb3fa54af2e513df","fromNode":"78caf5fed63cbd22","fromSide":"right","toNode":"ce76bc9bce0b50ad","toSide":"left"},
		{"id":"c0da53247a2b83b3","fromNode":"ce76bc9bce0b50ad","fromSide":"bottom","toNode":"1d903277b2dc30bc","toSide":"top"},
		{"id":"7037f35168621f0d","fromNode":"ce76bc9bce0b50ad","fromSide":"right","toNode":"51483552dbe489a3","toSide":"left"},
		{"id":"600ab0397d6e3807","fromNode":"1d903277b2dc30bc","fromSide":"right","toNode":"51483552dbe489a3","toSide":"left"},
		{"id":"d220683415d8698c","fromNode":"a43ace29c10f1fc8","fromSide":"right","toNode":"dd0245593cd1e586","toSide":"left","label":"1"},
		{"id":"72d95a903e996129","fromNode":"66097bfbff897244","fromSide":"top","toNode":"a43ace29c10f1fc8","toSide":"bottom","label":"1"},
		{"id":"0a2839eeb18bf0bc","fromNode":"b21834e1c1f7e368","fromSide":"bottom","toNode":"54c32f6d00c391d2","toSide":"top"},
		{"id":"e950ce1ed622cea0","fromNode":"c758a3145739bf25","fromSide":"right","toNode":"4672f9dfb5f191b8","toSide":"left"},
		{"id":"86b041a4c0294526","fromNode":"b21834e1c1f7e368","fromSide":"right","toNode":"5c06539dee86f17c","toSide":"left"},
		{"id":"c67078c7b32daff5","fromNode":"b21834e1c1f7e368","fromSide":"top","toNode":"c9f78a1fe486e1e3","toSide":"bottom","label":"梯度下降求解方法"},
		{"id":"eb117a50a920fd6f","fromNode":"c9f78a1fe486e1e3","fromSide":"right","toNode":"5362a8c30fa0e646","toSide":"left"},
		{"id":"b168e4fa07c469b3","fromNode":"5c06539dee86f17c","fromSide":"top","toNode":"5362a8c30fa0e646","toSide":"bottom"},
		{"id":"c1ea62ea1394e679","fromNode":"5362a8c30fa0e646","fromSide":"right","toNode":"c4db8c275a7622ea","toSide":"left","label":"实现"},
		{"id":"45692b3833689403","fromNode":"c4db8c275a7622ea","fromSide":"right","toNode":"62abef35d3820b2f","toSide":"left"},
		{"id":"060f7d2118e54073","fromNode":"62abef35d3820b2f","fromSide":"bottom","toNode":"222edf68dea49f40","toSide":"top","label":"根据模板生成的"},
		{"id":"8834966979bb4434","fromNode":"dd0245593cd1e586","fromSide":"right","toNode":"b21834e1c1f7e368","toSide":"left","label":"代码"},
		{"id":"8ffba2ec5cf9f0fa","fromNode":"a7f4859a6280c5e7","fromSide":"right","toNode":"b941c7b774c33402","toSide":"left"},
		{"id":"60f59c280e816bb5","fromNode":"48b05c35597e5551","fromSide":"bottom","toNode":"222edf68dea49f40","toSide":"right"},
		{"id":"e5f43dfb5f9671cb","fromNode":"48b05c35597e5551","fromSide":"left","toNode":"c758a3145739bf25","toSide":"top"},
		{"id":"e8f9d8264c93fb45","fromNode":"48b05c35597e5551","fromSide":"right","toNode":"cdd7b2b16c4a77b0","toSide":"left"},
		{"id":"71ea884a932addbf","fromNode":"cdd7b2b16c4a77b0","fromSide":"bottom","toNode":"4e47657f8d059ecc","toSide":"top"},
		{"id":"0d4189c7cafdda35","fromNode":"4e47657f8d059ecc","fromSide":"left","toNode":"aac756eb594c47e8","toSide":"right","label":"1"},
		{"id":"caf273f07b83a198","fromNode":"c758a3145739bf25","fromSide":"bottom","toNode":"aac756eb594c47e8","toSide":"top"},
		{"id":"7e7d1ee909886825","fromNode":"cb6291e8500e91f5","fromSide":"right","toNode":"aac756eb594c47e8","toSide":"left"},
		{"id":"3cc21dac2fd478fb","fromNode":"4e47657f8d059ecc","fromSide":"right","toNode":"f7835f1a6db8f5f8","toSide":"left","label":"2"},
		{"id":"8c85672d2104aa9c","fromNode":"aac756eb594c47e8","fromSide":"bottom","toNode":"27a208fb8e01d9b2","toSide":"top","label":"新位置文件"},
		{"id":"4218a8612a486eed","fromNode":"f7835f1a6db8f5f8","fromSide":"right","toNode":"fe210c40436e1b5e","toSide":"left"},
		{"id":"f99a07bb18356036","fromNode":"1d903277b2dc30bc","fromSide":"bottom","toNode":"2d056c1ed93a6abf","toSide":"left"},
		{"id":"d666e23a32833308","fromNode":"7c5e84aefb52d5d9","fromSide":"left","toNode":"03e0a566743b9a7c","toSide":"right"},
		{"id":"766a0e36a1e0fa31","fromNode":"27a208fb8e01d9b2","fromSide":"bottom","toNode":"7c5e84aefb52d5d9","toSide":"top","label":"branch1"},
		{"id":"8ff07542231ad6e2","fromNode":"7c5e84aefb52d5d9","fromSide":"right","toNode":"f7ffb8a7f232745c","toSide":"left"},
		{"id":"d21e36b30c83971b","fromNode":"7c5e84aefb52d5d9","fromSide":"bottom","toNode":"db1adccaec5b1185","toSide":"top"},
		{"id":"624227bf262fbab9","fromNode":"db1adccaec5b1185","fromSide":"left","toNode":"681bfb526b66f519","toSide":"right"},
		{"id":"a01f8044963b3a24","fromNode":"c758a3145739bf25","fromSide":"top","toNode":"92b565caa87fd42d","toSide":"bottom"},
		{"id":"9952ee39bed03b35","fromNode":"e3a43e329b08ff09","fromSide":"bottom","toNode":"2002fb028bd1738c","toSide":"top"},
		{"id":"6eef40af05987c2d","fromNode":"db1adccaec5b1185","fromSide":"right","toNode":"1cb785f04c8cb637","toSide":"left"},
		{"id":"3aa28ce9c6fc5d3b","fromNode":"db1adccaec5b1185","fromSide":"bottom","toNode":"ccbf1a09bb69825b","toSide":"top","label":"修改L2正则化"},
		{"id":"0a7183cb70275f91","fromNode":"2002fb028bd1738c","fromSide":"bottom","toNode":"984ce6de4c04052b","toSide":"top","label":"测试数据集"},
		{"id":"3e5378640ace9697","fromNode":"27a208fb8e01d9b2","fromSide":"left","toNode":"984ce6de4c04052b","toSide":"right","label":"测试数据集"},
		{"id":"1c325ed5d49f4d55","fromNode":"ccbf1a09bb69825b","fromSide":"left","toNode":"5a8d1048f671d7c2","toSide":"right"},
		{"id":"4d3779de23cecaea","fromNode":"ccbf1a09bb69825b","fromSide":"right","toNode":"e70205d32365e0cc","toSide":"left"},
		{"id":"d53b025edda6da8a","fromNode":"ccbf1a09bb69825b","fromSide":"bottom","toNode":"a4bdd3640a5b992d","toSide":"top","label":"修改学习率策略"},
		{"id":"f7f73f17407abd4b","fromNode":"e70205d32365e0cc","fromSide":"right","toNode":"8378539c4bf78ec3","toSide":"left"},
		{"id":"bcbc77069f37680c","fromNode":"8378539c4bf78ec3","fromSide":"bottom","toNode":"7b2efcbeb8aba4cd","toSide":"right"},
		{"id":"2fa5825f602bf05e","fromNode":"7b2efcbeb8aba4cd","fromSide":"left","toNode":"a4bdd3640a5b992d","toSide":"right"},
		{"id":"bd38e31144bc91bf","fromNode":"a4bdd3640a5b992d","fromSide":"bottom","toNode":"2cd50e2fa64f671f","toSide":"top","label":"修改预测步骤"},
		{"id":"a1a7d31d1e5b7b7e","fromNode":"d24e61fd9430995e","fromSide":"right","toNode":"36d233b84fe1f759","toSide":"left"},
		{"id":"ce66d7a752619549","fromNode":"36d233b84fe1f759","fromSide":"right","toNode":"2cd50e2fa64f671f","toSide":"left"},
		{"id":"de8911beb82baa95","fromNode":"2cd50e2fa64f671f","fromSide":"right","toNode":"85d2e4ffab4ee54e","toSide":"left"},
		{"id":"fa6a49dc4904b58b","fromNode":"46b2870115e6defb","fromSide":"bottom","toNode":"36d233b84fe1f759","toSide":"top"},
		{"id":"a84e8e3bfe775d80","fromNode":"7d4e5bda8eec6a51","fromSide":"right","toNode":"a4bdd3640a5b992d","toSide":"left"},
		{"id":"4c321fa378b2aec6","fromNode":"6ecdb4b050e1ec36","fromSide":"right","toNode":"984ce6de4c04052b","toSide":"left"},
		{"id":"d339d4563ced80de","fromNode":"27a208fb8e01d9b2","fromSide":"bottom","toNode":"3bdc4b61f9d1dcfd","toSide":"top","label":"branch2"},
		{"id":"479dcd2f98c9e64a","fromNode":"f9197833e777e578","fromSide":"right","toNode":"037acbd041fc5302","toSide":"left"},
		{"id":"937c55fb4112f7ef","fromNode":"037acbd041fc5302","fromSide":"right","toNode":"1ab1321707ff3802","toSide":"left"},
		{"id":"c248f18e048b8a1e","fromNode":"1ab1321707ff3802","fromSide":"bottom","toNode":"1c67654c7941ec60","toSide":"top","label":"数据检验"},
		{"id":"cf2db46df5e15089","fromNode":"1ab1321707ff3802","fromSide":"right","toNode":"1897f8cc01f49c64","toSide":"left"},
		{"id":"2569ff8a694bdf19","fromNode":"f9197833e777e578","fromSide":"bottom","toNode":"b2d593472a4fdc8a","toSide":"top"},
		{"id":"d6352162859aff6d","fromNode":"b2d593472a4fdc8a","fromSide":"right","toNode":"cfc437b44f436365","toSide":"left"},
		{"id":"767af31a37b8b794","fromNode":"cfc437b44f436365","fromSide":"right","toNode":"211407dcce738225","toSide":"left"},
		{"id":"8dffafac711ca12c","fromNode":"211407dcce738225","fromSide":"bottom","toNode":"2e9ec6ded179ed12","toSide":"top","label":"数据检验"},
		{"id":"f05c49d59a57430a","fromNode":"1226c15d83bc4205","fromSide":"right","toNode":"807f63c667280927","toSide":"left"},
		{"id":"5fb2620dc2107e43","fromNode":"807f63c667280927","fromSide":"right","toNode":"78b199854a9748d7","toSide":"left"},
		{"id":"8e06d431fc7f0158","fromNode":"e8686ca57b6a9908","fromSide":"bottom","toNode":"44aedd103c916c66","toSide":"top"},
		{"id":"64d29f9bdc698bb0","fromNode":"e8686ca57b6a9908","fromSide":"bottom","toNode":"061ea4cd47127324","toSide":"top"},
		{"id":"ca306172be99dc9c","fromNode":"b0ca9ceb71e805c1","fromSide":"right","toNode":"979b4fe91be09976","toSide":"left"},
		{"id":"16423f53addd916f","fromNode":"f9197833e777e578","fromSide":"left","toNode":"75493981c9b5c9aa","toSide":"top"},
		{"id":"79dc3f3dd602d01a","fromNode":"b2d593472a4fdc8a","fromSide":"left","toNode":"75493981c9b5c9aa","toSide":"top"},
		{"id":"ce72644fe4f160fb","fromNode":"b2d593472a4fdc8a","fromSide":"bottom","toNode":"052971c623105b30","toSide":"top"},
		{"id":"8971bf9bad39c05c","fromNode":"052971c623105b30","fromSide":"right","toNode":"1226c15d83bc4205","toSide":"left"},
		{"id":"d486e16ad92b7510","fromNode":"ebd5a5e899c111a0","fromSide":"right","toNode":"b0ca9ceb71e805c1","toSide":"left"},
		{"id":"eadd1ee00acb180c","fromNode":"052971c623105b30","fromSide":"bottom","toNode":"ebd5a5e899c111a0","toSide":"top"},
		{"id":"2c2fde27197de2a2","fromNode":"ebd5a5e899c111a0","fromSide":"left","toNode":"75493981c9b5c9aa","toSide":"top"},
		{"id":"7ea75503fbd5d6ed","fromNode":"979b4fe91be09976","fromSide":"bottom","toNode":"4fb5ee07ce9d60ce","toSide":"top"},
		{"id":"bb778991b9fa4f72","fromNode":"807f63c667280927","fromSide":"bottom","toNode":"f9f5c422424c5bdb","toSide":"top"},
		{"id":"dd9d1cb4961f816b","fromNode":"3bdc4b61f9d1dcfd","fromSide":"left","toNode":"75493981c9b5c9aa","toSide":"top"},
		{"id":"26f9b8b693932824","fromNode":"3bdc4b61f9d1dcfd","fromSide":"bottom","toNode":"f9197833e777e578","toSide":"top"},
		{"id":"9f07ae2661762f0a","fromNode":"3bdc4b61f9d1dcfd","fromSide":"right","toNode":"9f14879595285b06","toSide":"left"},
		{"id":"b1178fae28640f67","fromNode":"9f14879595285b06","fromSide":"right","toNode":"63e23d085f303857","toSide":"left"},
		{"id":"59b258ba3fd7ac74","fromNode":"27a208fb8e01d9b2","fromSide":"bottom","toNode":"186d5fb7ec18c912","toSide":"top","label":"branch3"},
		{"id":"fba99c3d65bd9bc1","fromNode":"bf70bc993d072134","fromSide":"bottom","toNode":"186d5fb7ec18c912","toSide":"top"},
		{"id":"0785fd1a91c912ec","fromNode":"8aa2be21512fb7a3","fromSide":"left","toNode":"b42eebc3b30843e2","toSide":"top"},
		{"id":"69a9f4621312d8c6","fromNode":"186d5fb7ec18c912","fromSide":"left","toNode":"b42eebc3b30843e2","toSide":"top"},
		{"id":"bb139c74f922b946","fromNode":"186d5fb7ec18c912","fromSide":"bottom","toNode":"8aa2be21512fb7a3","toSide":"top"},
		{"id":"c12b438bd0f31e65","fromNode":"186d5fb7ec18c912","fromSide":"right","toNode":"957cad6af09cc39c","toSide":"left"},
		{"id":"152b90212da010a1","fromNode":"8aa2be21512fb7a3","fromSide":"bottom","toNode":"6578bb79e4e7a292","toSide":"top"},
		{"id":"e7843f0264c4a6f4","fromNode":"8aa2be21512fb7a3","fromSide":"right","toNode":"18ac30104ba64cbb","toSide":"left"},
		{"id":"9b38790275e31a9a","fromNode":"6578bb79e4e7a292","fromSide":"right","toNode":"40abfe076834fda9","toSide":"left"},
		{"id":"845c2b9eef0aa798","fromNode":"6578bb79e4e7a292","fromSide":"bottom","toNode":"db6381ab3b4484fd","toSide":"top"},
		{"id":"132d1d4ead120e77","fromNode":"db6381ab3b4484fd","fromSide":"left","toNode":"b42eebc3b30843e2","toSide":"top"},
		{"id":"9f2c52352b6b488f","fromNode":"6578bb79e4e7a292","fromSide":"left","toNode":"b42eebc3b30843e2","toSide":"top"},
		{"id":"7e5fdd8ced80ff7c","fromNode":"db6381ab3b4484fd","fromSide":"right","toNode":"59815f198dec060e","toSide":"left"},
		{"id":"92624f6764d258e7","fromNode":"b42eebc3b30843e2","fromSide":"right","toNode":"9da6c869c88e65da","toSide":"left"},
		{"id":"97acfc07c2e94813","fromNode":"8e7e4f8a60ba1b6e","fromSide":"bottom","toNode":"09a4d25a775ccc82","toSide":"top"},
		{"id":"eaa77323c327ab93","fromNode":"75493981c9b5c9aa","fromSide":"right","toNode":"25fd344646b9c700","toSide":"left"},
		{"id":"4b6f6847a38016cc","fromNode":"1a99bade2627eba4","fromSide":"right","toNode":"b42eebc3b30843e2","toSide":"left"},
		{"id":"2f7a246b766cdbba","fromNode":"ce76bc9bce0b50ad","fromSide":"top","toNode":"b8deb3aa5b7a6005","toSide":"bottom"},
		{"id":"1456f5e9d67ccaf5","fromNode":"2c15712f06d9c4b8","fromSide":"bottom","toNode":"1003994ac4b35403","toSide":"top"},
		{"id":"01b6ee74b4e1172e","fromNode":"27a208fb8e01d9b2","fromSide":"bottom","toNode":"1003994ac4b35403","toSide":"top","label":"branch4"},
		{"id":"1de848c05d84f908","fromNode":"1003994ac4b35403","fromSide":"right","toNode":"927674bc04d2d987","toSide":"left"},
		{"id":"db2aaf4140a2da1b","fromNode":"1003994ac4b35403","fromSide":"bottom","toNode":"6945415c4d03a64a","toSide":"top","label":"重写梯度下降函数"},
		{"id":"ffa50bcd63194604","fromNode":"6945415c4d03a64a","fromSide":"bottom","toNode":"6bf2a78d4aa37561","toSide":"top","label":"使用branch1进行测试"},
		{"id":"0ef5966831c81eac","fromNode":"6bf2a78d4aa37561","fromSide":"bottom","toNode":"5014e2782b336901","toSide":"top"},
		{"id":"c7d0c6f22ed9ce03","fromNode":"1913fec9a54c3742","fromSide":"left","toNode":"2c15712f06d9c4b8","toSide":"right"},
		{"id":"aa965be7c8132dc8","fromNode":"4dbf5d1b495d845f","fromSide":"bottom","toNode":"f7835f1a6db8f5f8","toSide":"top"},
		{"id":"8f0036c60655ff40","fromNode":"61751582cd0f0823","fromSide":"left","toNode":"27a208fb8e01d9b2","toSide":"right"},
		{"id":"2d973d4b23d3d8fe","fromNode":"6bf2a78d4aa37561","fromSide":"right","toNode":"012da175781aa26e","toSide":"left"},
		{"id":"49bdf10a111f5f42","fromNode":"27a208fb8e01d9b2","fromSide":"right","toNode":"cfedd69d22654f1c","toSide":"left"},
		{"id":"a463a8385f58d964","fromNode":"012da175781aa26e","fromSide":"top","toNode":"cfedd69d22654f1c","toSide":"bottom"},
		{"id":"17243b2435da2fd9","fromNode":"cfedd69d22654f1c","fromSide":"right","toNode":"31e6aab4862322d8","toSide":"left","label":"主程序"},
		{"id":"eb53be27aa8172c3","fromNode":"31e6aab4862322d8","fromSide":"bottom","toNode":"9314bea0e3938840","toSide":"left","label":"改进模型"},
		{"id":"2b7dc4a1dca512e5","fromNode":"31e6aab4862322d8","fromSide":"bottom","toNode":"0d144526d4512afd","toSide":"left","label":"参数拟合步骤"},
		{"id":"8a53939aee2d92fa","fromNode":"31e6aab4862322d8","fromSide":"bottom","toNode":"8f511b14ac408c67","toSide":"left","label":"预测步骤"},
		{"id":"20a7f1e9f58954ae","fromNode":"31e6aab4862322d8","fromSide":"bottom","toNode":"9381d166460e5478","toSide":"left","label":"评估函数"},
		{"id":"78d2fde6309ba7bb","fromNode":"0c29ecb854d75bc7","fromSide":"top","toNode":"c00d3867944a87fe","toSide":"bottom"},
		{"id":"23ba7cc6f072b46b","fromNode":"0c29ecb854d75bc7","fromSide":"bottom","toNode":"034b1400999cf4c8","toSide":"top"}
	]
}